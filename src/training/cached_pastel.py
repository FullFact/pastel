"""Store questions, sentences, and answers in a database
This is useful for local experiments etc. but shouldn't be used (or useful) in production
"""

import logging
from typing import List, Optional, Set, Tuple

from pastel.models import FEATURE_TYPE, BiasType, Sentence
from pastel.pastel import ARRAY_TYPE, Pastel, feature_as_string
from training.db_manager import DatabaseManager

_logger = logging.getLogger(__name__)


class CachedPastel(Pastel):
    """
    A version of Pastel that caches responses in a database.
    Inherits from Pastel and overrides get_answers_to_questions to use caching.
    """

    def __init__(self, model: dict[FEATURE_TYPE, float]) -> None:
        """Initialize with questions and database connection."""
        super().__init__(model)
        self.db = DatabaseManager()

    @classmethod
    def from_pastel(cls, pastel: Pastel) -> "CachedPastel":
        """Create a CachedPastel instance from an existing Pastel object."""
        cached_pastel = cls(pastel.model)
        return cached_pastel

    def get_cached_questions(self) -> List[str]:
        """
        Get a list of all unique questions that have responses in the cache.

        Returns:
            List of questions that have been asked and cached, sorted alphabetically
        """
        return self.db.get_unique_questions()

    def _get_cached_responses(
        self, sentences: List[Sentence]
    ) -> List[List[Optional[float]]]:
        """
        Look up cached responses for a list of sentences and questions.

        Args:
            sentences: List of sentences to analyze

        Returns:
            List of lists, where each inner list contains the responses for a single sentence
        """
        responses = []

        for sentence in sentences:
            sentence_responses = []
            for question in self.get_questions():
                response = self.db.get_response(
                    question=feature_as_string(question),
                    sentence=sentence.sentence_text,
                )
                sentence_responses.append(response)
            # add in function calls here:
            for func in self.get_functions():
                response = func(sentence)
                sentence_responses.append(response)
            responses.append(sentence_responses)

        return responses

    def _get_responses_and_missing(
        self, sentences: List[Sentence]
    ) -> Tuple[List[List[Optional[float]]], Set[Sentence], Set[str]]:
        """
        Get (maybe incomplete) model responses for a list of sentences.
        Check what's in the database, and identify which sentences and questions have cached responses
        and which ones need new responses generated by the model.
        NOTE: this only handles questions (not functions) because function responses are not cached.

        Args:
            sentences: List of sentences to analyze

        Returns:
            Tuple containing:
            - List of lists of responses (including None for missing ones), where each inner list
              contains the responses for a single sentence
            - Set of unique sentences that need responses
            - Set of unique questions that need responses
        """
        # responses to any/all questions then any/all functions:
        responses = self._get_cached_responses(sentences)

        # Keep track of unique sentences and questions that need responses
        missing_sentences = set()
        missing_questions = set()

        # need to get questions (not functions)
        model_questions = self.get_questions()  # list(self.model.keys())

        # Iterate through all combinations to identify missing responses
        for i, sentence_responses in enumerate(responses):
            for j, response in enumerate(sentence_responses):
                if response is None:
                    missing_sentences.add(sentences[i])
                    missing_questions.add(model_questions[j])

        return responses, missing_sentences, missing_questions

    async def get_answers_to_questions(
        self, sentences: List[Sentence]
    ) -> dict[Sentence, dict[FEATURE_TYPE, float]]:
        """Embed each example into the prompt and pass to genAI.
        For each sentence, this Returns a dictionary mapping features to scores."""
        (
            responses,
            missing_sentences,
            missing_questions,
        ) = self._get_responses_and_missing(sentences)

        if missing_sentences and missing_questions:
            # Create subset model for missing questions
            # Explicitly construct the sub-model to satisfy mypy's expectations
            sub_model: dict[FEATURE_TYPE, float] = {BiasType.BIAS: self.get_bias()}
            for q in missing_questions:
                sub_model[q] = self.model[q]
            sub_pastel = Pastel(sub_model)
            new_answers: dict[Sentence, dict[FEATURE_TYPE, float]] = (
                await sub_pastel.get_answers_to_questions(list(missing_sentences))
            )
            answered_sentences = list(new_answers.keys())
            answer_array = sub_pastel.quantify_answers(list(new_answers.values()))

            actual_answers = answer_array[:, 1:]  # the first index is always the bias

            missing_questions_string: list[str] = [
                feature_as_string(q) for q in missing_questions
            ]
            # Note: some sentences in missing_sentences might still not have responses
            # so we only update sentences we *do* have answers for

            # Write new answers to database
            write_responses_to_db(
                questions=missing_questions_string,
                sentences=answered_sentences,
                responses=actual_answers,
                db=self.db,
            )

            # Everything should now be cached so let's get the final set of responses:
            (
                responses,
                missing_sentences,
                missing_questions,
            ) = self._get_responses_and_missing(sentences)

            no_questions_left = len(missing_questions) == 0
            assert no_questions_left, "There are still questions which need responses"

        # Build a typed feature list for zipping with responses in a mypy-friendly way
        features: List[FEATURE_TYPE] = [
            *self.get_questions(),
            *self.get_functions(),
        ]
        output = {
            sentence: {
                q: resp for q, resp in zip(features, responses[idx]) if resp is not None
            }
            for idx, sentence in enumerate(sentences)
        }

        # Convert list of lists to numpy array
        return output


def write_responses_to_db(
    questions: List[str],
    sentences: List[Sentence],
    responses: ARRAY_TYPE,
    db: Optional[DatabaseManager] = None,
) -> None:
    """
    Write multiple responses to the database.
    If any input is empty, the function returns without doing anything.

    Args:
        questions: List of questions that were asked
        sentences: List of sentences that were analyzed
        responses: 2D numpy array of responses, shape (n_sentences, n_questions)
                  Each value should be 0 (no), 1 (yes), or 0.5 (unsure)
        db: Optional DatabaseManager instance. If None, a new instance will be created
            (which will use the singleton pattern)

    Raises:
        ValueError: If the shape of responses doesn't match the number of questions and sentences
                   (only checked when inputs are non-empty)
    """
    # Handle empty inputs
    if not questions or not sentences or responses.size == 0:
        return

    if responses.shape != (len(sentences), len(questions)):
        raise ValueError(
            f"Response array shape {responses.shape} doesn't match "
            f"number of sentences ({len(sentences)}) and questions ({len(questions)})"
        )

    if db is None:
        db = DatabaseManager()

    # Write each response to the database
    for i, sentence in enumerate(sentences):
        for j, question in enumerate(questions):
            response_value = responses[i, j]
            db.write_response(question, sentence.sentence_text, response_value)
